{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seminar_syntax_mipt.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "OTq_sX298-ZR",
        "N7wiomoIvjc1",
        "JkApBJ9-TSdB",
        "8cUfzLy3Vxtj"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BQvyutTajsH"
      },
      "source": [
        "# Анализ тональности с рекурсивными нейросетями\n",
        "\n",
        "* [пост на медиуме](https://medium.com/@keisukeumezawa/chainer-tutorial-sentiment-analysis-with-recursive-neural-network-180ddde892a2)\n",
        "* [статья](https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf); архитектура описана в 4 секции\n",
        "* [демо с кликабельными картинками](http://nlp.stanford.edu:8080/sentiment/rntnDemo.html)\n",
        "* Код: [jupyter notebook](https://colab.research.google.com/github/chainer-community/chainer-colab-notebook/blob/master/official_example_en/sentiment.ipynb), [репозиторий](https://github.com/chainer/chainer/tree/master/examples/sentiment).\n",
        "\n",
        "\n",
        "В этой части используется идея *парсинга составляющих*, или *constituency parsing*. \n",
        "![Constituancy parsing](https://github.com/PragmaticsLab/NLP-course-AMI/raw/dev/seminars/sem5_syntax/constituency_parsing.png)\n",
        "\n",
        "Суть подхода к анализу тональности -- в том, что предложения складывается из сентимента его составляющих, а тех -- в свою очередь, из их составляющих (и не всегда конечный результат -- это простая сумма тональности кусков, как в модели мешка слов).\n",
        "\n",
        "![Sentiment recursive nn](https://github.com/PragmaticsLab/NLP-course-AMI/raw/dev/seminars/sem5_syntax/sentiment_recursiveNN.png)\n",
        "\n",
        "### Chainer\n",
        "\n",
        "Это ещё одна библиотека для глубокого обучения. Код этого туториала написан на ней.\n",
        "\n",
        "NB: нужно включить GPU.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7Stw2pRmp59",
        "outputId": "f0e0689e-8938-4cf6-b6d2-27c3c79e9e4a"
      },
      "source": [
        "!curl https://colab.chainer.org/install | sh -"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1580  100  1580    0     0   4831      0 --:--:-- --:--:-- --:--:--  4831\n",
            "+ apt -y -q install cuda-libraries-dev-10-0\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "cuda-libraries-dev-10-0 is already the newest version (10.0.130-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 30 not upgraded.\n",
            "+ pip install -q cupy-cuda100  chainer \n",
            "\u001b[K     |████████████████████████████████| 369.7MB 46kB/s \n",
            "\u001b[?25h+ set +ex\n",
            "Installation succeeded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Bz0IKWjnClm",
        "outputId": "1371cd41-29d5-4653-8b0d-eee0a1d51c23"
      },
      "source": [
        "import collections\n",
        "import numpy as np\n",
        "\n",
        "import chainer\n",
        "from chainer import cuda\n",
        "import chainer.functions as F\n",
        "import chainer.links as L\n",
        "from chainer.training import extensions\n",
        "from chainer import reporter\n",
        "\n",
        "\n",
        "chainer.print_runtime_info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/chainer/backends/cuda.py:147: UserWarning: cuDNN is not enabled.\n",
            "Please reinstall CuPy after you install cudnn\n",
            "(see https://docs-cupy.chainer.org/en/stable/install.html#install-cudnn).\n",
            "  'cuDNN is not enabled.\\n'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Platform: Linux-4.19.112+-x86_64-with-Ubuntu-18.04-bionic\n",
            "Chainer: 7.4.0\n",
            "ChainerX: Not Available\n",
            "NumPy: 1.19.5\n",
            "CuPy:\n",
            "  OS                           : Linux-4.19.112+-x86_64-with-Ubuntu-18.04-bionic\n",
            "  CuPy Version                 : 8.5.0\n",
            "  NumPy Version                : 1.19.5\n",
            "  SciPy Version                : 1.4.1\n",
            "  Cython Build Version         : 0.29.22\n",
            "  CUDA Root                    : /usr/local/cuda\n",
            "  CUDA Build Version           : 10000\n",
            "  CUDA Driver Version          : 11020\n",
            "  CUDA Runtime Version         : 10000\n",
            "  cuBLAS Version               : 10000\n",
            "  cuFFT Version                : 10000\n",
            "  cuRAND Version               : 10000\n",
            "  cuSOLVER Version             : (10, 0, 0)\n",
            "  cuSPARSE Version             : 10000\n",
            "  NVRTC Version                : (10, 0)\n",
            "  Thrust Version               : 100903\n",
            "  CUB Build Version            : 100800\n",
            "  cuDNN Build Version          : 7605\n",
            "  cuDNN Version                : 7605\n",
            "  NCCL Build Version           : 2604\n",
            "  NCCL Runtime Version         : 2604\n",
            "  cuTENSOR Version             : None\n",
            "  Device 0 Name                : Tesla T4\n",
            "  Device 0 Compute Capability  : 75\n",
            "iDeep: 2.0.0.post3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdNxNhdWmw11"
      },
      "source": [
        "### Данные\n",
        "\n",
        "Мы используем Penn Treebank, размеченный по тональностям."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWMAi2i6ZnN6"
      },
      "source": [
        "import os.path\n",
        "from six.moves.urllib import request\n",
        "import zipfile\n",
        "\n",
        "\n",
        "request.urlretrieve(\n",
        "    'https://nlp.stanford.edu/sentiment/trainDevTestTrees_PTB.zip',\n",
        "    'trainDevTestTrees_PTB.zip')\n",
        "zf = zipfile.ZipFile('trainDevTestTrees_PTB.zip')\n",
        "for name in zf.namelist():\n",
        "    (dirname, filename) = os.path.split(name)\n",
        "    if not filename == '':\n",
        "        zf.extract(name, '.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYwxeeW7oExg",
        "outputId": "dd6b21c6-88d9-4043-de96-27ef46afff68"
      },
      "source": [
        "!ls trees"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dev.txt  test.txt  train.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgHShekGpPsK"
      },
      "source": [
        "Посмотрим на первую строку `test.txt`: как и нужно для нашей задачи, по тональности размечена каждый узел дерева. Для разметки групп используется скобочная нотация."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Hmj1Z1wo8L9",
        "outputId": "08883494-2581-4331-c9a6-d872c3e79947"
      },
      "source": [
        "!head trees/dev.txt -n1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3 (2 It) (4 (4 (2 's) (4 (3 (2 a) (4 (3 lovely) (2 film))) (3 (2 with) (4 (3 (3 lovely) (2 performances)) (2 (2 by) (2 (2 (2 Buy) (2 and)) (2 Accorsi))))))) (2 .)))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PfxwIY1rCQs"
      },
      "source": [
        "Дерево размечено рекурсивно в формате `(value, node)`, где `value` -- метка класса тональности. В датасете 5 классов тональности: от 0 до 4, где 0 -- самая отрицательная, а 4 -- самая положительная."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjBUS6Cr8Sye"
      },
      "source": [
        "### 2. Setting parameters\n",
        "Here we set the parameters for training.\n",
        "* `` n_epoch``: Epoch number. How many times we pass through the whole training data.\n",
        "* `` n_units``: Number of units. How many hidden state units each Recursive Neural Network node has.\n",
        "* `` batchsize``: Batch size. How many train data we will input as a block when updating parameters.\n",
        "* `` n_label``: Number of labels. Number of classes to be identified. Since there are 5 labels this time, `` 5``.\n",
        "* `` epoch_per_eval``: How often to perform validation.\n",
        "* `` is_test``: If `` True``, we use a small dataset.\n",
        "* `` gpu_id``: GPU ID. The ID of the GPU to use. For Colaboratory it is good to use `` 0``."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ha6-ramShVF"
      },
      "source": [
        "# parameters\n",
        "n_epoch = 100  # number of epochs\n",
        "n_units = 30  # number of units per layer\n",
        "batchsize = 25  # minibatch size\n",
        "n_label = 5  # number of labels\n",
        "epoch_per_eval = 5  # number of epochs per evaluation\n",
        "is_test = True\n",
        "gpu_id = 0\n",
        "\n",
        "if is_test:\n",
        "    max_size = 10\n",
        "else:\n",
        "    max_size = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3PnMSM78akB"
      },
      "source": [
        "### 3. Preparing the iterator\n",
        "\n",
        "Let's read the dataset used for training, validation, test and create an Iterator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ermPnCx061Hq"
      },
      "source": [
        "First, we convert each sample represented by ``str`` type to a tree structure data represented by a ``dictionary`` type.\n",
        "\n",
        "We will tokenize the string with `` read_corpus`` implemented by the parser `` SexpParser``. After that, we convert each tokenized sample to a tree structure data  by `` convert_tree``. By doing like this, it is possible to express a label as ``int``, a node as a two-element ``tuple``, and a tree structure as a ``dictionary``, making it a more manageable data structure than the original string.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqEzpAzMeMVo"
      },
      "source": [
        "import codecs\n",
        "import re\n",
        "\n",
        "\n",
        "class SexpParser(object):\n",
        "\n",
        "    def __init__(self, line):\n",
        "        self.tokens = re.findall(r'\\(|\\)|[^\\(\\) ]+', line)\n",
        "        self.pos = 0\n",
        "\n",
        "    def parse(self):\n",
        "        assert self.pos < len(self.tokens)\n",
        "        token = self.tokens[self.pos]\n",
        "        assert token != ')'\n",
        "        self.pos += 1\n",
        "\n",
        "        if token == '(':\n",
        "            children = []\n",
        "            while True:\n",
        "                assert self.pos < len(self.tokens)\n",
        "                if self.tokens[self.pos] == ')':\n",
        "                    self.pos += 1\n",
        "                    break\n",
        "                else:\n",
        "                    children.append(self.parse())\n",
        "            return children\n",
        "        else:\n",
        "            return token\n",
        "\n",
        "\n",
        "def read_corpus(path, max_size):\n",
        "    with codecs.open(path, encoding='utf-8') as f:\n",
        "        trees = []\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            tree = SexpParser(line).parse()\n",
        "            trees.append(tree)\n",
        "            if max_size and len(trees) >= max_size:\n",
        "                break\n",
        "\n",
        "    return trees\n",
        "\n",
        "  \n",
        "def convert_tree(vocab, exp):\n",
        "    assert isinstance(exp, list) and (len(exp) == 2 or len(exp) == 3)\n",
        "\n",
        "    if len(exp) == 2:\n",
        "        label, leaf = exp\n",
        "        if leaf not in vocab:\n",
        "            vocab[leaf] = len(vocab)\n",
        "        return {'label': int(label), 'node': vocab[leaf]}\n",
        "    elif len(exp) == 3:\n",
        "        label, left, right = exp\n",
        "        node = (convert_tree(vocab, left), convert_tree(vocab, right))\n",
        "        return {'label': int(label), 'node': node}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrP2AfaqXmpm"
      },
      "source": [
        "Let's use `` read_corpus () `` and `` convert_tree () `` to create an iterator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b316yW_dBBho"
      },
      "source": [
        "test_trees = read_corpus('trees/dev.txt', max_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7iuyz9sBWZm",
        "outputId": "b4996ea4-9fa3-4294-a8c7-367f3c0fe451"
      },
      "source": [
        "test_trees[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['3',\n",
              " ['2', 'It'],\n",
              " ['4',\n",
              "  ['4',\n",
              "   ['2', \"'s\"],\n",
              "   ['4',\n",
              "    ['3', ['2', 'a'], ['4', ['3', 'lovely'], ['2', 'film']]],\n",
              "    ['3',\n",
              "     ['2', 'with'],\n",
              "     ['4',\n",
              "      ['3', ['3', 'lovely'], ['2', 'performances']],\n",
              "      ['2',\n",
              "       ['2', 'by'],\n",
              "       ['2', ['2', ['2', 'Buy'], ['2', 'and']], ['2', 'Accorsi']]]]]]],\n",
              "  ['2', '.']]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42l-fDBfRijd"
      },
      "source": [
        "vocab = {}\n",
        "    \n",
        "train_data = [convert_tree(vocab, tree) \n",
        "                        for tree in read_corpus('trees/train.txt', max_size)]\n",
        "train_iter = chainer.iterators.SerialIterator(train_data, batchsize)\n",
        "\n",
        "validation_data = [convert_tree(vocab, tree) \n",
        "                                 for tree in read_corpus('trees/dev.txt', max_size)]\n",
        "validation_iter = chainer.iterators.SerialIterator(validation_data, batchsize, \n",
        "                                                                                   repeat=False, shuffle=False)\n",
        "\n",
        "test_data = [convert_tree(vocab, tree) \n",
        "                        for tree in read_corpus('trees/test.txt', max_size)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xE3MSUrj92Tn"
      },
      "source": [
        "Let's try to display the first element of `` test_data``. It is represented by the following tree structure, `` lable`` expresses the score of that `` node``, and the numerical value of the leaf `` node`` corresponds to the word id in the dictionary `` vocab``."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aE4YORp2eQP9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bedc933-2621-43f6-9885-3f9d5db0537a"
      },
      "source": [
        "test_data[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 2,\n",
              " 'node': ({'label': 3,\n",
              "   'node': ({'label': 3, 'node': 252}, {'label': 2, 'node': 71})},\n",
              "  {'label': 1,\n",
              "   'node': ({'label': 1, 'node': 253}, {'label': 2, 'node': 254})})}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVUZPtjo8ycv"
      },
      "source": [
        "\n",
        "### 4. Preparing the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr0cD269R8Ga"
      },
      "source": [
        "#### Рекурсивная нейросеть\n",
        "\n",
        "Recursive Neural Networks -- это нейросети, которые работают с данными переменной длины, используя иерархические структуры (деревья).\n",
        "Скрытое состояние i-той вершины дерева вычисляются из скрытых состояний её левого и правого ребёнка:\n",
        "\n",
        "![recursive nn_formula](https://github.com/PragmaticsLab/NLP-course-AMI/raw/dev/seminars/sem5_syntax/recursiveNN_formula.jpg)\n",
        "![recursive nn](https://github.com/PragmaticsLab/NLP-course-AMI/raw/dev/seminars/sem5_syntax/recursiveNN.jpg)\n",
        "\n",
        "Векторные представления фраз (узлов дерева) подаются на вход слою-классификатору тональности и softmax (в обучающем датасете все составляющие размечены по тональности)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eU55nEkoE_Kc"
      },
      "source": [
        "В методе `traverse` мы рекурсивно обходим все узлы дерева, на каждом шаге подсчитывая значение функции потерь `loss`.\n",
        "\n",
        "\n",
        "В первую очередь, мы получаем вектор скрытого состояния `` v``. Если мы имеем дело с листом (то есть конкретным словом), мы получаем его эмбеддинг с помощью метода `model.leaf(word)`, который получает на вход id слова. А если мы обрабатываесм внутренний узел дерева, мы получаем вектор `v` из векторов его детей (`` left`` и `` right``) в строке `` v = model.node(left, right)`` с помощью рекурсивной нейросети, описанной выше.\n",
        "\n",
        "`` loss += F.softmax_cross_entropy(y, t) `` вычисляет значение функции потерь для текущего узла. Это значение будет сложено с суммой значений функции потерь для детей этого узла, и, впоследствии, передано родителю, чтобы вычислить `loss` для всего дерева.\n",
        "\n",
        "After the line `` loss += F.softmax_cross_entropy(y, t)``, there are some lines for logging accuracy and etc. But it is not necessary for the model definition itself."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGICf_k0hzW8"
      },
      "source": [
        "class RecursiveNet(chainer.Chain):\n",
        "\n",
        "    def __init__(self, n_vocab, n_units):\n",
        "        super(RecursiveNet, self).__init__()\n",
        "        with self.init_scope():\n",
        "\n",
        "            # обучаемый слой эмбеддингов\n",
        "            self.embed = L.EmbedID(n_vocab, n_units)\n",
        "\n",
        "            # слой для соединения эмбеддингов левого и правого детей \n",
        "            self.l = L.Linear(n_units * 2, n_units)\n",
        "\n",
        "            # слой для получения id класса\n",
        "            self.w = L.Linear(n_units, n_label)\n",
        "  \n",
        "    def traverse(self, node, evaluate=None, root=True):\n",
        "        if isinstance(node['node'], int):\n",
        "            # leaf node\n",
        "            word = self.xp.array([node['node']], np.int32)\n",
        "            loss = 0\n",
        "            v = model.leaf(word)\n",
        "        else:\n",
        "            # internal node\n",
        "            left_node, right_node = node['node']\n",
        "            left_loss, left = self.traverse(left_node, evaluate=evaluate, root=False)\n",
        "            right_loss, right = self.traverse(right_node, evaluate=evaluate, root=False)\n",
        "            v = model.node(left, right)\n",
        "            loss = left_loss + right_loss\n",
        "\n",
        "        y = model.label(v)\n",
        "\n",
        "        label = self.xp.array([node['label']], np.int32)\n",
        "        t = chainer.Variable(label)\n",
        "        loss += F.softmax_cross_entropy(y, t)\n",
        "\n",
        "        predict = cuda.to_cpu(y.data.argmax(1))\n",
        "        if predict[0] == node['label']:\n",
        "            evaluate['correct_node'] += 1\n",
        "        evaluate['total_node'] += 1\n",
        "  \n",
        "        if root:\n",
        "            if predict[0] == node['label']:\n",
        "                evaluate['correct_root'] += 1\n",
        "            evaluate['total_root'] += 1\n",
        "\n",
        "        return loss, v\n",
        "\n",
        "    def leaf(self, x):\n",
        "        return self.embed(x)\n",
        "\n",
        "    def node(self, left, right):\n",
        "        return F.tanh(self.l(F.concat((left, right))))\n",
        "\n",
        "    def label(self, v):\n",
        "        return self.w(v)\n",
        "    \n",
        "    def __call__(self, x):\n",
        "        # эквивалент forward в pytorch\n",
        "        accum_loss = 0.0\n",
        "        result = collections.defaultdict(lambda: 0)\n",
        "        for tree in x:\n",
        "            loss, _ = self.traverse(tree, evaluate=result)\n",
        "            accum_loss += loss\n",
        "        \n",
        "        reporter.report({'loss': accum_loss}, self)\n",
        "        reporter.report({'total': result['total_node']}, self)\n",
        "        reporter.report({'correct': result['correct_node']}, self)\n",
        "        return accum_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYsIEJUI_Km4"
      },
      "source": [
        "\n",
        "Data `` x`` is passed to `` __call__`` is mini-batched input data and contains samples `` s_n`` like `` [s_1, s_2, ..., s_N] ``."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnBhdpO8igK9"
      },
      "source": [
        "model = RecursiveNet(len(vocab), n_units)\n",
        "\n",
        "if gpu_id >= 0:\n",
        "    model.to_gpu()\n",
        "\n",
        "# Setup optimizer\n",
        "optimizer = chainer.optimizers.AdaGrad(lr=0.1)\n",
        "optimizer.setup(model)\n",
        "optimizer.add_hook(chainer.optimizer_hooks.WeightDecay(0.0001))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTq_sX298-ZR"
      },
      "source": [
        "### 5. Preparation and training of Updater · Trainer\n",
        "\n",
        "We define an updater and a trainer to train the model. For details on `MicroAverage`, please refer to [chainer.training.extensions.MicroAverage](https://docs.chainer.org/en/latest/reference/generated/chainer.training.extensions.MicroAverage.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXAIZSy9cQdu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eae8a630-43fa-4e19-8424-16d8478b6440"
      },
      "source": [
        "def _convert(batch, device):\n",
        "  return batch\n",
        "\n",
        "updater = chainer.training.StandardUpdater(\n",
        "    train_iter, optimizer, device=gpu_id, converter=_convert)\n",
        "\n",
        "trainer = chainer.training.Trainer(updater, (n_epoch, 'epoch'))\n",
        "trainer.extend(\n",
        "        extensions.Evaluator(validation_iter, model, device=gpu_id, converter=_convert),\n",
        "        trigger=(epoch_per_eval, 'epoch'))\n",
        "trainer.extend(extensions.LogReport())\n",
        "\n",
        "trainer.extend(extensions.MicroAverage(\n",
        "        'main/correct', 'main/total', 'main/accuracy'))\n",
        "trainer.extend(extensions.MicroAverage(\n",
        "        'validation/main/correct', 'validation/main/total',\n",
        "        'validation/main/accuracy'))\n",
        "\n",
        "trainer.extend(extensions.PrintReport(\n",
        "        ['epoch', 'main/loss', 'validation/main/loss',\n",
        "          'main/accuracy', 'validation/main/accuracy', 'elapsed_time']))\n",
        "trainer.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch       main/loss   validation/main/loss  main/accuracy  validation/main/accuracy  elapsed_time\n",
            "\u001b[J2           2189.86                           0.126437                                 8.77634       \n",
            "\u001b[J5           1359.14     611.41                0.550964       0.431694                  11.4808       \n",
            "\u001b[J7           1074.56                           0.706369                                 14.0959       \n",
            "\u001b[J10          838.312     674.703               0.747774       0.461749                  16.6282       \n",
            "\u001b[J12          808.377                           0.782326                                 19.0214       \n",
            "\u001b[J15          652.84      606.255               0.850655       0.483607                  21.939        \n",
            "\u001b[J17          396.665                           0.927993                                 24.4548       \n",
            "\u001b[J20          284.214     662.818               0.96303        0.469945                  27.235        \n",
            "\u001b[J22          208.014                           0.97351                                  29.5829       \n",
            "\u001b[J25          176.411     693.419               0.984523       0.47541                   32.5109       \n",
            "\u001b[J27          135.538                           0.988341                                 34.9713       \n",
            "\u001b[J30          107.869     711.361               0.995475       0.469945                  37.7497       \n",
            "\u001b[J32          90.6726                           1                                        40.2293       \n",
            "\u001b[J35          73.619      728.701               0.997194       0.478142                  42.921        \n",
            "\u001b[J37          64.0959                           1                                        45.2971       \n",
            "\u001b[J40          54.8888     744.541               1              0.478142                  48.0259       \n",
            "\u001b[J42          47.7381                           1                                        50.4975       \n",
            "\u001b[J45          42.2352     756.792               1              0.47541                   53.1431       \n",
            "\u001b[J47          37.8275                           1                                        55.4802       \n",
            "\u001b[J50          33.4492     767.352               1              0.47541                   58.2576       \n",
            "\u001b[J52          29.0329                           1                                        60.5976       \n",
            "\u001b[J55          29.3678     775.348               1              0.478142                  63.4732       \n",
            "\u001b[J57          24.9458                           1                                        65.7899       \n",
            "\u001b[J60          24.1985     781.911               1              0.486339                  68.7447       \n",
            "\u001b[J62          22.4871                           1                                        71.3162       \n",
            "\u001b[J65          19.692      787.023               1              0.489071                  74.1844       \n",
            "\u001b[J67          18.3182                           1                                        76.5622       \n",
            "\u001b[J70          18.4642     790.975               1              0.486339                  79.3688       \n",
            "\u001b[J72          15.5943                           1                                        81.649        \n",
            "\u001b[J75          16.915      794.267               1              0.486339                  84.5302       \n",
            "\u001b[J77          14.368                            1                                        86.9064       \n",
            "\u001b[J80          14.6779     796.837               1              0.486339                  89.7197       \n",
            "\u001b[J82          12.9236                           1                                        92.0285       \n",
            "\u001b[J85          13.2735     798.784               1              0.489071                  94.9199       \n",
            "\u001b[J87          11.6576                           1                                        97.2186       \n",
            "\u001b[J90          12.1579     800.297               1              0.489071                  100.08        \n",
            "\u001b[J92          11.1877                           1                                        102.449       \n",
            "\u001b[J95          10.6141     801.456               1              0.489071                  105.179       \n",
            "\u001b[J97          10.4643                           1                                        107.728       \n",
            "\u001b[J100         9.60885     802.289               1              0.497268                  110.438       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7wiomoIvjc1"
      },
      "source": [
        "### 6. Checking the performance with test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4g1JkNWv86t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "babefd3b-3bbd-45f2-fa24-d4fb31815f97"
      },
      "source": [
        "def evaluate(model, test_trees):\n",
        "    result = collections.defaultdict(lambda: 0)\n",
        "    with chainer.using_config('train', False), chainer.no_backprop_mode():\n",
        "        for tree in test_trees:\n",
        "            model.traverse(tree, evaluate=result)\n",
        "    acc_node = 100.0 * result['correct_node'] / result['total_node']\n",
        "    acc_root = 100.0 * result['correct_root'] / result['total_root']\n",
        "    print(' Node accuracy: {0:.2f} %% ({1:,d}/{2:,d})'.format(\n",
        "        acc_node, result['correct_node'], result['total_node']))\n",
        "    print(' Root accuracy: {0:.2f} %% ({1:,d}/{2:,d})'.format(\n",
        "        acc_root, result['correct_root'], result['total_root']))\n",
        "            \n",
        "print('Test evaluation')\n",
        "evaluate(model, test_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test evaluation\n",
            " Node accuracy: 54.49 %% (170/312)\n",
            " Root accuracy: 50.00 %% (5/10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlIYS65qKx1C"
      },
      "source": [
        "NB: в секции с определением параметров, мы указали `is_test = True`, а значит, обучающий датасет состоял всего из 10 предложений, поэтому результаты такие плохие. При желании, можно увеличить размер обучающей выборки."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBfAx998TFHf"
      },
      "source": [
        "# Парсинг зависимостей с UDPipe\n",
        "\n",
        "* наша цель -- представить предложение естественного языка в виде дерева\n",
        "* слова предложения -- вершины; *зависимости (dependencies)* между ними -- рёбра\n",
        "* зависимости могут быть разными: например, субъект глагола, объект глагола, прилагательное-модификатор, и так далее\n",
        "\n",
        "### Формат\n",
        "\n",
        "Существует несколько форматов записи деревьев зависимостей, но самый популярный и общеиспользуемый -- [CoNLL-U](http://universaldependencies.org/format.html).<br/>\n",
        "Как это выглядит (пример из [русского Universal Dependency трибанка](https://github.com/UniversalDependencies/UD_Russian-SynTagRus)):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mk-jvM63TS0O"
      },
      "source": [
        "my_example = \"\"\"\n",
        "# sent_id = 2003Armeniya.xml_138\n",
        "# text = Перспективы развития сферы высоких технологий.\n",
        "1\tПерспективы\tперспектива\tNOUN\t_\tAnimacy=Inan|Case=Nom|Gender=Fem|Number=Plur\t0\tROOT\t0:root\t_\n",
        "2\tразвития\tразвитие\tNOUN\t_\tAnimacy=Inan|Case=Gen|Gender=Neut|Number=Sing\t1\tnmod\t1:nmod\t_\n",
        "3\tсферы\tсфера\tNOUN\t_\tAnimacy=Inan|Case=Gen|Gender=Fem|Number=Sing\t2\tnmod\t2:nmod\t_\n",
        "4\tвысоких\tвысокий\tADJ\t_\tCase=Gen|Degree=Pos|Number=Plur\t5\tamod\t5:amod\t_\n",
        "5\tтехнологий\tтехнология\tNOUN\t_\tAnimacy=Inan|Case=Gen|Gender=Fem|Number=Plur\t3\tnmod\t3:nmod\tSpaceAfter=No\n",
        "6\t.\t.\tPUNCT\t_\t_\t1\tpunct\t1:punct\t_\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkApBJ9-TSdB"
      },
      "source": [
        "Комментарии + таблица c 9 колонками (разделители табы):\n",
        "* ID\n",
        "* FORM: токен\n",
        "* LEMMA: начальная форма\n",
        "* UPOS: универсальная часть речи\n",
        "* XPOS: лингво-специфичная часть речи\n",
        "* FEATS: морфологическая информация: падеж, род, число etc\n",
        "* HEAD: id ролителя\n",
        "* DEPREL: тип зависимости, то есть отношение к токену-родителю\n",
        "* DEPS: альтернативный подграф (не будем углубляться :))\n",
        "* MISC: всё остальное\n",
        "\n",
        "Отсутствующие данные представляются с помощью `_`. Больше подробностей про формат -- в [официальной документаци](http://universaldependencies.org/format.html).<br>\n",
        "\n",
        "Отрытый инструмент для визуализации, ручной разметки и конвертации в другие форматы: UD Annotatrix. [Online-интерфейс](https://maryszmary.github.io/ud-annotatrix/standalone/annotator.html), [репозиторий](https://github.com/jonorthwash/ud-annotatrix).\n",
        "\n",
        "Трибанк -- много таких предложений. Обычно они разделяются двумя переносами строки.\n",
        "### Как считывать данные в питоне\n",
        "\n",
        "Используем библиотеку [conllu](https://github.com/EmilStenstrom/conllu)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uMH-frXTcUc",
        "outputId": "445b0777-9528-45f3-ea37-3e5824fc7473"
      },
      "source": [
        "!pip3 install conllu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting conllu\n",
            "  Downloading https://files.pythonhosted.org/packages/ae/be/be6959c3ff2dbfdd87de4be0ccdff577835b5d08b1d25bf7fd4aaf0d7add/conllu-4.4-py2.py3-none-any.whl\n",
            "Installing collected packages: conllu\n",
            "Successfully installed conllu-4.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FLLazWFTiVo"
      },
      "source": [
        "from conllu import parse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hc2AljTtTkLA",
        "outputId": "2d5abcd4-8eeb-4f16-d127-6fb38a5baea3"
      },
      "source": [
        "sentences = parse(my_example)\n",
        "sentence = sentences[0]\n",
        "sentence[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'deprel': 'ROOT',\n",
              " 'deps': [('root', 0)],\n",
              " 'feats': {'Animacy': 'Inan',\n",
              "  'Case': 'Nom',\n",
              "  'Gender': 'Fem',\n",
              "  'Number': 'Plur'},\n",
              " 'form': 'Перспективы',\n",
              " 'head': 0,\n",
              " 'id': 1,\n",
              " 'lemma': 'перспектива',\n",
              " 'misc': None,\n",
              " 'upos': 'NOUN',\n",
              " 'xpos': None}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COtZB8LpTxqy"
      },
      "source": [
        "## Визуализация\n",
        "\n",
        "В nltk есть DependencyGraph, который умеет рисовать деревья (и ещё многое другое). Для того, чтобы визуализация работала корректно, ему нужна зависимость: graphviz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJdwXHeSTnE0",
        "outputId": "04e7c39d-0017-4053-e50a-66e5693a3b6f"
      },
      "source": [
        "!apt-get install graphviz\n",
        "!pip install graphviz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "graphviz is already the newest version (2.40.1-2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 30 not upgraded.\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (0.10.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dp8SSx2NT0Yj"
      },
      "source": [
        "from nltk import DependencyGraph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4xMRcLjT7-f"
      },
      "source": [
        "В отличие от `conllu`, `DependencyGraph` не справляется с комментариями, поэтому придётся их убрать. Кроме того ему обязательно нужен `deprel` *ROOT* в верхнем регистре, иначе он не находит корень.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6TxwD4QT2Yk"
      },
      "source": [
        "sents = []\n",
        "for sent in my_example.split('\\n\\n'):\n",
        "    # убираем коменты\n",
        "    sent = '\\n'.join([line for line in sent.split('\\n') if not line.startswith('#')])\n",
        "    # заменяем deprel для root\n",
        "    sent = sent.replace('\\troot\\t', '\\tROOT\\t')\n",
        "    sents.append(sent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "LBPR-L3qT_Js",
        "outputId": "d85f90dd-4930-4101-e64f-542b2a963f27"
      },
      "source": [
        "graph = DependencyGraph(tree_str=sents[0])\n",
        "graph"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DependencyGraph with 7 nodes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: G Pages: 1 -->\n<svg width=\"180pt\" height=\"479pt\"\n viewBox=\"0.00 0.00 179.50 479.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 475)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-475 175.5,-475 175.5,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<text text-anchor=\"middle\" x=\"98.5\" y=\"-449.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">0 (None)</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<text text-anchor=\"middle\" x=\"98.5\" y=\"-362.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">1 (Перспективы)</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M98.5,-434.9735C98.5,-423.1918 98.5,-407.5607 98.5,-394.1581\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"102.0001,-394.0033 98.5,-384.0034 95.0001,-394.0034 102.0001,-394.0033\"/>\n<text text-anchor=\"middle\" x=\"118.5\" y=\"-405.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">ROOT</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<text text-anchor=\"middle\" x=\"53.5\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">2 (развития)</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M89.176,-347.9735C82.9009,-335.8418 74.5148,-319.6287 67.4499,-305.9698\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"70.5151,-304.2776 62.8121,-297.0034 64.2976,-307.4935 70.5151,-304.2776\"/>\n<text text-anchor=\"middle\" x=\"96.5\" y=\"-318.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n</g>\n<!-- 6 -->\n<g id=\"node4\" class=\"node\">\n<title>6</title>\n<text text-anchor=\"middle\" x=\"144.5\" y=\"-275.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">6 (.)</text>\n</g>\n<!-- 1&#45;&gt;6 -->\n<g id=\"edge3\" class=\"edge\">\n<title>1&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M108.0312,-347.9735C114.4457,-335.8418 123.0182,-319.6287 130.2401,-305.9698\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"133.4008,-307.4797 134.981,-297.0034 127.2126,-304.2077 133.4008,-307.4797\"/>\n<text text-anchor=\"middle\" x=\"140\" y=\"-318.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">punct</text>\n</g>\n<!-- 3 -->\n<g id=\"node5\" class=\"node\">\n<title>3</title>\n<text text-anchor=\"middle\" x=\"53.5\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">3 (сферы)</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge4\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M53.5,-260.9735C53.5,-249.1918 53.5,-233.5607 53.5,-220.1581\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"57.0001,-220.0033 53.5,-210.0034 50.0001,-220.0034 57.0001,-220.0033\"/>\n<text text-anchor=\"middle\" x=\"70.5\" y=\"-231.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<text text-anchor=\"middle\" x=\"53.5\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">5 (технологий)</text>\n</g>\n<!-- 3&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>3&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M53.5,-173.9735C53.5,-162.1918 53.5,-146.5607 53.5,-133.1581\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"57.0001,-133.0033 53.5,-123.0034 50.0001,-133.0034 57.0001,-133.0033\"/>\n<text text-anchor=\"middle\" x=\"70.5\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">nmod</text>\n</g>\n<!-- 4 -->\n<g id=\"node7\" class=\"node\">\n<title>4</title>\n<text text-anchor=\"middle\" x=\"53.5\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">4 (высоких)</text>\n</g>\n<!-- 5&#45;&gt;4 -->\n<g id=\"edge6\" class=\"edge\">\n<title>5&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M53.5,-86.9735C53.5,-75.1918 53.5,-59.5607 53.5,-46.1581\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"57.0001,-46.0033 53.5,-36.0034 50.0001,-46.0034 57.0001,-46.0033\"/>\n<text text-anchor=\"middle\" x=\"70\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">amod</text>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kkRNBVFU47T"
      },
      "source": [
        "## UDPipe\n",
        "\n",
        "[UDPipe](http://ufal.mff.cuni.cz/udpipe) умеет парсить текст с помощью готовых моделей (которые можно скачать [здесь](https://github.com/jwijffels/udpipe.models.ud.2.0/tree/master/inst/udpipe-ud-2.0-170801)) и обучать модели на своих трибанках.\n",
        "\n",
        "Собственно, в UDPipe -- это пайплайн из следующих моделей:\n",
        "* сегментатор и токенизатор (разделить текст на предложения, предложения на токены, сделать заготовку таблицы для для CoNLL-U)\n",
        "* тэггер (разметить части речи)\n",
        "* лемматизатор\n",
        "* сам парсер (сопоставить каждому токену `head` и `deprel`)\n",
        "\n",
        "Мы сегодня не будем обучать новых моделей (это слишком долго), а используем готовую модель для русского. Кроме русского, у UDPipe есть модели [для многих других языков]((https://github.com/jwijffels/udpipe.models.ud.2.0/tree/master/inst/udpipe-ud-2.0-170801)). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cUfzLy3Vxtj"
      },
      "source": [
        "### The Python binding\n",
        "\n",
        "UDPipe можно использовать через command-line interface и с помощью питоновской обвязки. Она довольно [плохо задокументирована](https://pypi.org/project/ufal.udpipe/), но зато можно использовать прямо в питоне, поэтому сегодня воспользуемся ей :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ip2aufnrUBmi",
        "outputId": "2952b340-f5c2-4b50-f3d7-fe7d50352994"
      },
      "source": [
        "!pip install ufal.udpipe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ufal.udpipe\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/72/2b8b9dc7c80017c790bb3308bbad34b57accfed2ac2f1f4ab252ff4e9cb2/ufal.udpipe-1.2.0.3.tar.gz (304kB)\n",
            "\r\u001b[K     |█                               | 10kB 23.3MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20kB 16.7MB/s eta 0:00:01\r\u001b[K     |███▎                            | 30kB 10.4MB/s eta 0:00:01\r\u001b[K     |████▎                           | 40kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 51kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 61kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 71kB 9.5MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 81kB 9.8MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 92kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 102kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 112kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 122kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 133kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 143kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 153kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 163kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 174kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 184kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 194kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 204kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 215kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 225kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 235kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 245kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 256kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 266kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 276kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 286kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 296kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 307kB 8.7MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: ufal.udpipe\n",
            "  Building wheel for ufal.udpipe (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ufal.udpipe: filename=ufal.udpipe-1.2.0.3-cp37-cp37m-linux_x86_64.whl size=5626595 sha256=ba327db04d290b93165b0305f558265e39a09e8a18eb422ea4e60ffc8910c000\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/9d/db/6d3404c33da5b7adb6c6972853efb6a27649d3ba15f7e9bebb\n",
            "Successfully built ufal.udpipe\n",
            "Installing collected packages: ufal.udpipe\n",
            "Successfully installed ufal.udpipe-1.2.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26I6l8InWAf6"
      },
      "source": [
        "from ufal.udpipe import Model, Pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHctc9PGWFi-"
      },
      "source": [
        "Скачиваем легкую (хоть и не очень хорошую) модель для русского:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mukjYrbeWCGb",
        "outputId": "25e91400-ac72-47e7-b273-1e0c1b9a51fc"
      },
      "source": [
        "!wget https://github.com/jwijffels/udpipe.models.ud.2.0/raw/master/inst/udpipe-ud-2.0-170801/russian-ud-2.0-170801.udpipe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-24 22:06:11--  https://github.com/jwijffels/udpipe.models.ud.2.0/raw/master/inst/udpipe-ud-2.0-170801/russian-ud-2.0-170801.udpipe\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/jwijffels/udpipe.models.ud.2.0/master/inst/udpipe-ud-2.0-170801/russian-ud-2.0-170801.udpipe [following]\n",
            "--2021-03-24 22:06:11--  https://raw.githubusercontent.com/jwijffels/udpipe.models.ud.2.0/master/inst/udpipe-ud-2.0-170801/russian-ud-2.0-170801.udpipe\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13265262 (13M) [application/octet-stream]\n",
            "Saving to: ‘russian-ud-2.0-170801.udpipe’\n",
            "\n",
            "russian-ud-2.0-1708 100%[===================>]  12.65M  58.5MB/s    in 0.2s    \n",
            "\n",
            "2021-03-24 22:06:12 (58.5 MB/s) - ‘russian-ud-2.0-170801.udpipe’ saved [13265262/13265262]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziPvYewNWQKc"
      },
      "source": [
        "Загружаем модель"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7T5B3-IwWRfc"
      },
      "source": [
        "model = Model.load(\"russian-ud-2.0-170801.udpipe\") # path to the model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCRAeSxbXyCA",
        "outputId": "3cf30027-2818-46f3-a05a-e6ba1c965e1a"
      },
      "source": [
        "# если успех, должно быть так (model != None)\n",
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Swig Object of type 'model *' at 0x7f34e1782df0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSP2T8qrXz5g",
        "outputId": "59b1df01-5165-4386-f95d-73341693e8e4"
      },
      "source": [
        "pipeline = Pipeline(model, 'generic_tokenizer', '', '', '')\n",
        "example = \"\"\"А кто уроки не учил,\n",
        "Тому несдобровать в ночи.\n",
        "Кто плохо ел и поздно лег,\n",
        "К тому приходит русский рок\"\"\"\n",
        "parsed = pipeline.process(example)\n",
        "print(parsed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# newdoc\n",
            "# newpar\n",
            "# sent_id = 1\n",
            "# text = А кто уроки не учил, Тому несдобровать в ночи.\n",
            "1\tА\tА\tCCONJ\tCC\t_\t5\tcc:preconj\t_\t_\n",
            "2\tкто\tкТО\tPRON\tWP\tAnimacy=Anim|Case=Nom|Gender=Masc|Number=Sing\t5\tnsubj\t_\t_\n",
            "3\tуроки\tуроки\tNOUN\tNN\tAnimacy=Anim|Case=Nom|Gender=Masc|Number=Plur\t5\tnsubj\t_\t_\n",
            "4\tне\tНЕ\tPART\tNEG\tPolarity=Neg\t5\tadvmod\t_\t_\n",
            "5\tучил\tучил\tVERB\tVBC\tAspect=Perf|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin\t0\troot\t_\tSpaceAfter=No\n",
            "6\t,\t,\tPUNCT\t,\t_\t8\tpunct\t_\tSpacesAfter=\\n\n",
            "7\tТому\tТОТ\tSCONJ\tIN\t_\t8\tmark\t_\t_\n",
            "8\tнесдобровать\tнесдобровать\tVERB\tVB\tAspect=Imp|VerbForm=Inf\t5\txcomp\t_\t_\n",
            "9\tв\tВ\tADP\tIN\t_\t10\tcase\t_\t_\n",
            "10\tночи\tНОЧЬ\tNOUN\tNN\tAnimacy=Inan|Case=Gen|Gender=Fem|Number=Sing\t8\tobl\t_\tSpaceAfter=No\n",
            "11\t.\t.\tPUNCT\t.\t_\t5\tpunct\t_\tSpacesAfter=\\n\n",
            "\n",
            "# sent_id = 2\n",
            "# text = Кто плохо ел и поздно лег, К тому приходит русский рок\n",
            "1\tКто\tКТО\tPRON\tWP\tAnimacy=Anim|Case=Nom|Gender=Masc|Number=Sing\t3\tnsubj\t_\t_\n",
            "2\tплохо\tПЛОХО\tADV\tRB\t_\t3\tadvmod\t_\t_\n",
            "3\tел\tел\tVERB\tVBC\tAspect=Imp|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin\t0\troot\t_\t_\n",
            "4\tи\tИ\tCCONJ\tCC\t_\t6\tcc\t_\t_\n",
            "5\tпоздно\tпоздно\tADV\tRB\t_\t6\tadvmod\t_\t_\n",
            "6\tлег\tЛЕГ\tNOUN\tNN\tAnimacy=Inan|Case=Nom|Gender=Masc|Number=Sing\t10\tconj\t_\tSpaceAfter=No\n",
            "7\t,\t,\tPUNCT\t,\t_\t10\tpunct\t_\tSpacesAfter=\\n\n",
            "8\tК\tК\tADP\tIN\t_\t9\tcase\t_\t_\n",
            "9\tтому\tТО\tPRON\tDT\tAnimacy=Inan|Case=Dat|Gender=Neut|Number=Sing\t10\tobl\t_\t_\n",
            "10\tприходит\tПРИХОДИТЬ\tVERB\tVBC\tAspect=Imp|Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\t3\tconj\t_\t_\n",
            "11\tрусский\tРУССКИЙ\tADJ\tJJL\tAnimacy=Inan|Case=Nom|Gender=Masc|Number=Sing\t12\tamod\t_\t_\n",
            "12\tрок\tрок\tNOUN\tNN\tAnimacy=Inan|Case=Nom|Gender=Masc|Number=Sing\t10\tnsubj\t_\tSpacesAfter=\\n\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPJHNDrcX8QP"
      },
      "source": [
        "Как видим, UDPipe и токенизировал, и лематизировал текст, сделал POS-tagging и, собственно, синтаксический парсинг.\n",
        "\n",
        "Можно скопировать и вставить предложения в [онлайн-визуализатор](https://maryszmary.github.io/ud-annotatrix/standalone/annotator.html), чтобы посмотреть, что вышло."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bF0jqC1rqO8l"
      },
      "source": [
        "## Natasha\n",
        "\n",
        "Natasha так же умеет делать синтаксический парсинг для русского языка:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfZa16NNqarG",
        "outputId": "4155ac92-7e15-4ffe-82bf-7dbd943048d5"
      },
      "source": [
        "!pip install natasha"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting natasha\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/8e/ab0745100be276750fb6b8858c6180a1756696572295a74eb5aea77f3bbd/natasha-1.4.0-py3-none-any.whl (34.4MB)\n",
            "\u001b[K     |████████████████████████████████| 34.4MB 75kB/s \n",
            "\u001b[?25hCollecting yargy>=0.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/46/bc1a17200a55f4b0608f39ac64f1840fd4a52f9eeea462d9afecbf71246b/yargy-0.15.0-py3-none-any.whl (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.6MB/s \n",
            "\u001b[?25hCollecting slovnet>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/3b/f1ef495be8990004959dd0510c95f688d1b07529f6a862bc56a405770b26/slovnet-0.5.0-py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.7MB/s \n",
            "\u001b[?25hCollecting ipymarkup>=0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bf/9b/bf54c98d50735a4a7c84c71e92c5361730c878ebfe903d2c2d196ef66055/ipymarkup-0.9.0-py3-none-any.whl\n",
            "Collecting navec>=0.9.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/c1/771ec5565f0ce24874d7fd325b429f9caa80517a40d2e4ce5705120591f3/navec-0.10.0-py3-none-any.whl\n",
            "Collecting razdel>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/15/2c/664223a3924aa6e70479f7d37220b3a658765b9cfe760b4af7ffdc50d38f/razdel-0.5.0-py3-none-any.whl\n",
            "Collecting pymorphy2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/57/b2ff2fae3376d4f3c697b9886b64a54b476e1a332c67eee9f88e7f1ae8c9/pymorphy2-0.9.1-py3-none-any.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from slovnet>=0.3.0->natasha) (1.19.5)\n",
            "Collecting intervaltree>=3\n",
            "  Downloading https://files.pythonhosted.org/packages/50/fb/396d568039d21344639db96d940d40eb62befe704ef849b27949ded5c3bb/intervaltree-3.1.0.tar.gz\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/79/bea0021eeb7eeefde22ef9e96badf174068a2dd20264b9a378f2be1cdd9e/pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2MB 29.5MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha) (0.6.2)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.3.0)\n",
            "Building wheels for collected packages: intervaltree\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26102 sha256=41e0d4571e16b8a73737406985530d0d2a96e034384e44d5b8347852e6d2c636\n",
            "  Stored in directory: /root/.cache/pip/wheels/f3/f2/66/e9c30d3e9499e65ea2fa0d07c002e64de63bd0adaa49c445bf\n",
            "Successfully built intervaltree\n",
            "Installing collected packages: pymorphy2-dicts-ru, dawg-python, pymorphy2, yargy, navec, razdel, slovnet, intervaltree, ipymarkup, natasha\n",
            "  Found existing installation: intervaltree 2.1.0\n",
            "    Uninstalling intervaltree-2.1.0:\n",
            "      Successfully uninstalled intervaltree-2.1.0\n",
            "Successfully installed dawg-python-0.7.2 intervaltree-3.1.0 ipymarkup-0.9.0 natasha-1.4.0 navec-0.10.0 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844 razdel-0.5.0 slovnet-0.5.0 yargy-0.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6M2rwP3OqUD0"
      },
      "source": [
        "from natasha import Doc, NewsEmbedding, NewsSyntaxParser, Segmenter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__kZSge9qUaz",
        "outputId": "8dab6b19-e197-43d1-8975-8ab2ac5574ba"
      },
      "source": [
        "example = \"Я смотрел, как Си-лучи мерцают во тьме близ врат Тангейзера. Все эти мгновения исчезнут во времени, как слёзы под дождём. \"\n",
        "doc = Doc(example)\n",
        "doc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Doc(text='Я смотрел, как Си-лучи мерцают во тьме близ врат ...)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eICa3fLOq7_J"
      },
      "source": [
        "Предварительный (и обязательный!) этап - сплиттинг (разбиение на предложения):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3QSzClFqWOp",
        "outputId": "bddc59c6-e4d2-46b9-b84c-53bdc0323346"
      },
      "source": [
        "segmenter = Segmenter()\n",
        "\n",
        "doc.segment(segmenter)\n",
        "doc.sents"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[DocSent(stop=60, text='Я смотрел, как Си-лучи мерцают во тьме близ врат ..., tokens=[...]),\n",
              " DocSent(start=61, stop=121, text='Все эти мгновения исчезнут во времени, как слёзы ..., tokens=[...])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vs0XS6k6rAM4"
      },
      "source": [
        "emb = NewsEmbedding()\n",
        "syntax_parser = NewsSyntaxParser(emb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3O-D2tjrDmg"
      },
      "source": [
        "doc.parse_syntax(syntax_parser)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "FhFmQLyttmv4",
        "outputId": "62c1ea8b-cd0f-407d-ada1-ab88827737fc"
      },
      "source": [
        "display(doc.tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[DocToken(stop=1, text='Я', id='1_1', head_id='1_2', rel='nsubj'),\n",
              " DocToken(start=2, stop=9, text='смотрел', id='1_2', head_id='1_0', rel='root'),\n",
              " DocToken(start=9, stop=10, text=',', id='1_3', head_id='1_6', rel='punct'),\n",
              " DocToken(start=11, stop=14, text='как', id='1_4', head_id='1_6', rel='mark'),\n",
              " DocToken(start=15, stop=22, text='Си-лучи', id='1_5', head_id='1_6', rel='obj'),\n",
              " DocToken(start=23, stop=30, text='мерцают', id='1_6', head_id='1_2', rel='ccomp'),\n",
              " DocToken(start=31, stop=33, text='во', id='1_7', head_id='1_10', rel='case'),\n",
              " DocToken(start=34, stop=38, text='тьме', id='1_8', head_id='1_6', rel='obl'),\n",
              " DocToken(start=39, stop=43, text='близ', id='1_9', head_id='1_10', rel='case'),\n",
              " DocToken(start=44, stop=48, text='врат', id='1_10', head_id='1_11', rel='amod'),\n",
              " DocToken(start=49, stop=59, text='Тангейзера', id='1_11', head_id='1_10', rel='nmod'),\n",
              " DocToken(start=59, stop=60, text='.', id='1_12', head_id='1_2', rel='punct'),\n",
              " DocToken(start=61, stop=64, text='Все', id='2_1', head_id='2_3', rel='det'),\n",
              " DocToken(start=65, stop=68, text='эти', id='2_2', head_id='2_3', rel='det'),\n",
              " DocToken(start=69, stop=78, text='мгновения', id='2_3', head_id='2_4', rel='nsubj'),\n",
              " DocToken(start=79, stop=87, text='исчезнут', id='2_4', head_id='2_0', rel='root'),\n",
              " DocToken(start=88, stop=90, text='во', id='2_5', head_id='2_6', rel='case'),\n",
              " DocToken(start=91, stop=98, text='времени', id='2_6', head_id='2_4', rel='obl'),\n",
              " DocToken(start=98, stop=99, text=',', id='2_7', head_id='2_9', rel='punct'),\n",
              " DocToken(start=100, stop=103, text='как', id='2_8', head_id='2_9', rel='case'),\n",
              " DocToken(start=104, stop=109, text='слёзы', id='2_9', head_id='2_6', rel='acl'),\n",
              " DocToken(start=110, stop=113, text='под', id='2_10', head_id='2_11', rel='case'),\n",
              " DocToken(start=114, stop=120, text='дождём', id='2_11', head_id='2_9', rel='nmod'),\n",
              " DocToken(start=120, stop=121, text='.', id='2_12', head_id='2_4', rel='punct')]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQUASjPetsfR",
        "outputId": "6cc7c421-7ef7-4e3f-a92e-9c5fbbae2c2b"
      },
      "source": [
        "doc.sents[0].syntax.print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        ┌► Я          nsubj\n",
            "┌─┌─────└─ смотрел    \n",
            "│ │ ┌────► ,          punct\n",
            "│ │ │ ┌──► как        mark\n",
            "│ │ │ │ ┌► Си-лучи    obj\n",
            "│ └►└─└─└─ мерцают    ccomp\n",
            "│ ┌►│      во         case\n",
            "│ │ └────► тьме       obl\n",
            "│ │     ┌► близ       case\n",
            "│ └─┌─┌►└─ врат       amod\n",
            "│   └►└─── Тангейзера nmod\n",
            "└────────► .          punct\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpdRP8hdulkE",
        "outputId": "f74f022b-27c3-4094-e3b2-8bccfd6d3bf6"
      },
      "source": [
        "doc.sents[1].syntax.print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      ┌──► Все       det\n",
            "      │ ┌► эти       det\n",
            "      └─└─ мгновения nsubj\n",
            "┌───┌─└─── исчезнут  \n",
            "│   │   ┌► во        case\n",
            "│ ┌─└──►└─ времени   obl\n",
            "│ │   ┌──► ,         punct\n",
            "│ │   │ ┌► как       case\n",
            "│ └►┌─└─└─ слёзы     acl\n",
            "│   │   ┌► под       case\n",
            "│   └──►└─ дождём    nmod\n",
            "└────────► .         punct\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkygdmOUurZZ"
      },
      "source": [
        "Можно посмотреть на детали разбора:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYkCWhO7uqwE",
        "outputId": "ad30670b-a793-44e3-ef20-71eef7e7a50d"
      },
      "source": [
        "doc.sents[0].syntax.tokens[3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SyntaxToken(\n",
              "    id='1_4',\n",
              "    text='как',\n",
              "    head_id='1_6',\n",
              "    rel='mark'\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdfIYKthU6yP"
      },
      "source": [
        "## Доп. материал\n",
        "\n",
        "* [статья про синтаксический пробинг BERT](https://nlp.stanford.edu//~johnhew//structural-probe.html)"
      ]
    }
  ]
}